///*
//// 25/11/2015 : kostasl Testing OpenCV bg substraction - to process larva in vial recording timelapses.
 //// App uses BG substyraction MOG2, with a slow learning rate.
 //// then Uses Open and Close / Dilation contraction techniques to get rid of noise and fill gaps
 //// Then uses cvBlob library to track and count larva on BG-processed images.
 //// The lib sources have been included to the source and slightly modified in update tracks to fix a bug.
 ////
 ///* User:
 ///* Chooses input video file, then on the second dialogue choose the text file to export track info in CSV format.
 ///* The green box defines the region over which the larvae are counted-tracked and recorded to file.
 ///* Once the video begins to show, use to left mouse clicks to define a new region in the image over which you want to count the larvae.
 ///* Press p to pause Image. once paused:
 ///*  s to save snapshots in CSV outdir pics subfolder.
 ///*  2 Left Clicks to define the 2 points of region-of interest for tracking.
 ///*  m to show the masked image of the larva against BG.
 ///*  t Start Tracking
 ///*  q Exit Quit application
 ///*
 ///* NOTE: Changing ROI hits SEG. FAULTs in update tracks of the library. So I made setting of ROI only once.
 ///* The Area is locked after t is pressed to start tracking. Still it fails even if I do it through cropping the images.
 ///* So I reverted to not tracking - as the code does not work well - I am recording blobs For now
 ///*
 ///*  Dependencies : opencv3
 ///*
 /// TODO: Detect stopped Larva - either pupating or stuck
 ////////


#include <larvatrack.h>
#include <QDirIterator>
#include <QDir>
#include <QDebug>


#include <opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>
//#include <opencv2/bgsegm.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/video/background_segm.hpp>

#include <GUI/mainwindow.h>

//Global Variables
QElapsedTimer gTimer;
QString outfilename;
std::string gstrwinName;
QString gstroutDirCSV; //The Output Directory

cv::Mat inputframe; //current frame
cv::Mat frame; //current frame
cv::Mat frameMasked; //copy of Current frame;
cv::Mat framefishMasked; //copy of Current frame;
cv::Mat fgMask; //fg mask generated by calc BG Method
cv::Mat fgMaskFish; //fg mask containing FIsh blob
cv::Mat fgMaskMOG; //fg mask fg mask generated by MOG2 method
cv::Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method

cv::Ptr<cv::BackgroundSubtractor> pMOG; //MOG Background subtractor
cv::Ptr<cv::BackgroundSubtractorMOG2> pMOG2; //MOG2 Background subtractor
cv::Ptr<cv::BackgroundSubtractorKNN> pKNN; //MOG Background subtractor
//cv::Ptr<cv::bgsegm::BackgroundSubtractorGMG> pGMG; //GMG Background subtractor

cv::Mat kernelOpen;
cv::Mat kernelOpenLaplace;
cv::Mat kernelOpenfish;
cv::Mat kernelClose;



//Global Shortcut of Type conversion to legacy IplImage
IplImage  *labelImg;
IplImage frameImg;
IplImage framefishMaskImg;


ltROI Circle( cv::Point(0,0) , cv::Point(1024,768));
ltROIlist vRoi;
cv::Point ptROI1;
cv::Point ptROI2;

//Structures to hold blobs & Tracks
cvb::CvBlobs blobs; //All Blobs
cvb::CvBlobs fishblobs;
cvb::CvBlobs foodblobs;
const unsigned int thresh_fishblobarea = 800;

cvb::CvTracks tracks;

//Font for Reporting - Tracking
CvFont trackFnt;



int keyboard; //input from keyboard
int screenx,screeny;
bool showMask; //True will show the BGSubstracted IMage/Processed Mask
bool bROIChanged;
bool bPaused;
bool bExiting;
bool bTracking;
bool bSaveImages = false;
bool b1stPointSet;
bool bMouseLButtonDown;


//Area Filters
double dMeanBlobArea = 300;
double dVarBlobArea = 50;

//BG History
const int MOGhistory        = 150.0;
//Processing Loop delay
uint cFrameDelayms    = 1;
float gfVidfps        = 150;
double dLearningRate        = 1.0/(5.0*MOGhistory);

//Segmentation Params
int g_Segthresh = 10; //Image Threshold for FIsh Features
int g_BGthresh = 31; //BG threshold segmentation
//using namespace std;


int main(int argc, char *argv[])
{
    bROIChanged = false;
    bPaused = true;
    showMask = false;
    bTracking = false;
    bExiting    = false;

    QApplication app(argc, argv);
    //QQmlApplicationEngine engine;
    MainWindow window_main;

    window_main.show();
    //window_main.showFullScreen();

    //outfilename.truncate(outfilename.lastIndexOf("."));
    QString outfilename = QFileDialog::getSaveFileName(0, "Save tracks to output","VX_pos.csv", "CSV files (*.csv);", 0, 0); // getting the filename (full path)
    //QString outDir = outfilename.left(outfilename.lastIndexOf('/') ).toStdString().c_str();
    gstroutDirCSV = outfilename.left(outfilename.lastIndexOf("/"));
    std::cout << "Csv Output Dir is " << gstroutDirCSV.toStdString()  << "\n " <<std::endl;

    // get the applications dir pah and expose it to QML
    //engine.load(QUrl(QStringLiteral("qrc:///main.qml")));
    //Init Font
    cvInitFont(&trackFnt, CV_FONT_HERSHEY_DUPLEX, 0.4, 0.4, 0, 1);


    gTimer.start();
    //create GUI windows
    gstrwinName = "FishFrame";
    cv::namedWindow(gstrwinName,CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
    cv::namedWindow(gstrwinName + " FG Mask",CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
    cv::namedWindow(gstrwinName + " FishOnly",CV_WINDOW_NORMAL | CV_WINDOW_KEEPRATIO);
    //set the callback function for any mouse event
    cv::setMouseCallback(gstrwinName, CallBackFunc, NULL);

    cv::createTrackbar( "Laplace Size:", gstrwinName + " FishOnly", &g_BGthresh, 31.0, thresh_callback );
    cv::createTrackbar( "Fish Threshold:", gstrwinName + " FishOnly", &g_Segthresh, 151.0, thresh_callback );

    thresh_callback( 0, 0 );


    //Initialize The Track and blob vectors
    cvb::cvReleaseTracks(tracks);
    cvb::cvReleaseBlobs(blobs);



    /// create Background Subtractor objects
    //(int history=500, double varThreshold=16, bool detectShadows=true
    //OPENCV 3
    pMOG2 =  cv::createBackgroundSubtractorMOG2(MOGhistory,16,false);
    //(int history=200, int nmixtures=5, double backgroundRatio=0.7, double noiseSigma=0)
    //pMOG =   cv::bgsegm::createBackgroundSubtractorMOG(MOGhistory,12,0.05,0.00); //MOG approach
     //pKNN = cv::createBackgroundSubtractorKNN(MOGhistory,50,false);
//    pGMG =   cv::bgsegm::createBackgroundSubtractorGMG(MOGhistory,0.3); //GMG approach

    ///* Create Morphological Kernel Elements used in processFrame *///
    kernelOpen      = cv::getStructuringElement(cv::MORPH_CROSS,cv::Size(3,3),cv::Point(-1,-1));
    kernelOpenLaplace = cv::getStructuringElement(cv::MORPH_CROSS,cv::Size(1,1),cv::Point(-1,-1));
    kernelOpenfish  = cv::getStructuringElement(cv::MORPH_ELLIPSE,cv::Size(5,5),cv::Point(-1,-1));
    kernelClose     = cv::getStructuringElement(cv::MORPH_CROSS,cv::Size(3,3),cv::Point(-1,-1));


    //unsigned int hWnd = cvGetWindowHandle(sgstrwinName);
    try{ //If cv is compiled with QT support //Remove otherwise
        //cv::setWindowTitle(strwinName, outfilename.toStdString());
        //cv::displayOverlay(strwinName,"Tracking: " + outfilename.toStdString(), 20000 );
        //trackVideofiles(window_main);

    }catch(int e)
    {
        std::cerr << "OpenCV not compiled with QT support! can display overlay" <<std::endl;
    }

    //trackImageSequencefiles(window_main);
    trackVideofiles(window_main);
    //destroy GUI windows
    cv::destroyAllWindows();
    cv::waitKey(0);                                          // Wait for a keystroke in the window

    //pMOG->~BackgroundSubtractor();
    pMOG2->~BackgroundSubtractor();
    //pKNN->~BackgroundSubtractor();
    //pGMG->~BackgroundSubtractor();

    //Empty The Track and blob vectors
    cvb::cvReleaseTracks(tracks);
    cvb::cvReleaseBlobs(blobs);



    std::cout << "Total processing time : mins " << gTimer.elapsed()/60000.0 << std::endl;

    app.quit();

    return app.exec();

}



unsigned int trackVideofiles(MainWindow& window_main)
{

    QString invideoname = "*.mpg";
    unsigned int istartFrame = 0;
    QStringList invideonames =QFileDialog::getOpenFileNames(0, "Select timelapse video to Process",gstroutDirCSV.toStdString().c_str(), "Video file (*.mpg *.avi *.mp4 *.h264 *.mkv *.tiff *.png *.jpg *.pgm)", 0, 0);

    //Show Video list to process
    std::cout << "Video List To process:" <<std::endl;
    for (int i = 0; i<invideonames.size() && i < 10; ++i)
    {
       invideoname = invideonames.at(i);
       std::cout << "*" <<  invideoname.toStdString() << std::endl;
    }

    //Go through Each Image/Video - Hold Last Frame N , make it the start of the next vid.
    for (int i = 0; i<invideonames.size(); ++i)
    {

       invideoname = invideonames.at(i);
       std::cout << " Now Processing : "<< invideoname.toStdString() <<std::endl;


       getBGModelFromVideo(fgMask, window_main,invideoname,outfilename,istartFrame);

       std::cout << "Press r to run Video processing" << std::endl;

       istartFrame = processVideo(fgMask,window_main,invideoname,outfilename,istartFrame);

       window_main.setWindowTitle("Tracking:" + invideoname);

        if (istartFrame == 0)
        {
            std::cerr << "Could not load last video - Exiting loop." <<std::endl;
            break;
        }
    }
    return istartFrame;
}


unsigned int trackImageSequencefiles(MainWindow& window_main)
{

    QString inVideoDirname = QFileDialog::getExistingDirectory(&window_main,"Select folder with video images to track", gstroutDirCSV);

    unsigned int istartFrame = 0;
    unsigned int nFrame = 0;

    QStringList strImageNames; //Save Passed Files Here

    qDebug() << "Open File Sequence in : " << inVideoDirname;

    ///* Obtain BG Model LOOP//////////////
        //QDirIterator itBGimgDir(inVideoDirname, QDirIterator::Subdirectories);
        QStringList fileFilters; fileFilters << "*.png" << "*.tiff" << "*.pgm" << "*.png";
        QStringList imgFiles = QDir(inVideoDirname).entryList(fileFilters,QDir::Files,QDir::Name);
        inVideoDirname.append('/');
        QListIterator<QString> itfile (imgFiles);
        while (itfile.hasNext() && !bExiting)
        {
          QString filename = itfile.next();
          qDebug() << filename;
          std::string filepath = filename.prepend(inVideoDirname ).toStdString();
          //std::cout << filepath << std::endl;

          frame  = cv::imread(filepath , CV_LOAD_IMAGE_COLOR);
          //Contrast Brightness
          //frame.convertTo(frame, -1, 1, 0); //increase the contrast (double)

          nFrame++;
          if (!updateBGFrame(frame,fgMask,nFrame)) //Stop when BG learning says so
            break;

          /// Display Output //
          frameMasked = cv::Mat::zeros(frameMasked.rows, frameMasked.cols, CV_8U);
          frame.copyTo(frameMasked,fgMask);
          ///Display Output
          cv::imshow(gstrwinName,frameMasked);

          window_main.showVideoFrame(frame,nFrame); //Show On QT Window

          cv::imshow(gstrwinName + " FG Mask", fgMask);



          //Check For input Control
          keyboard = cv::waitKey( cFrameDelayms );
          checkPauseRun(window_main,keyboard,nFrame);
        }


    ///LOOP Tracking Process images with Obtained BG Model - Now Start over images afresh
    nFrame = 0;

    //Show Video list to process
    //Go through Each Video - Hold Last Frame N , make it the start of the next vid.
    std::cout << "Starting Tracking  processing" << std::endl;


    itfile.toFront();
    while (itfile.hasNext() && !bExiting)
    {
      QString filename = itfile.next();
      qDebug() << filename;
      std::string filepath = filename.prepend(inVideoDirname).toStdString();

      //std::cout << filepath << std::endl;

       frame  = cv::imread(filepath , CV_LOAD_IMAGE_COLOR);
       if (!frame.data)
       {
            std::cerr << "Could not open next Image frame." << std::endl;
            std::exit(EXIT_FAILURE);
       }
       //if (frame.depth() < 3) //Need To increase depth if we are to paint on this frame
       //     cv::cvtColor( frame, frame, cv::COLOR_GRAY2RGB);

       //Contrast Brightness
       //frame.convertTo(frame, -1, 1.2, 0); //increase the contrast (double)
       nFrame++;

      // std::cout << " Now Processing : "<< itimgDir.fileName().toStdString() ;

       /// Frame The Fish ///
       frameMasked = cv::Mat::zeros(frame.rows, frame.cols,CV_8U);
       //frameMasked.convertTo(frameMasked, -1, 0.3, 0); //increase the contrast (double)
       frame.copyTo(frameMasked,fgMask);

       cv::imshow(gstrwinName,frameMasked);

       processFrame(frame,fgMask,frameMasked,nFrame);


       ///Display Output //
       cv::imshow(gstrwinName + " FishOnly",framefishMasked);

       window_main.showVideoFrame(frame,nFrame); //Show On QT Window

       if (showMask)
       {
            cv::imshow(gstrwinName + " FG Mask", fgMask);
            cv::imshow(gstrwinName + " FG Fish Mask", fgMaskFish);
       }


       window_main.setWindowTitle("Tracking:" + filename);
       keyboard = cv::waitKey( cFrameDelayms );
       checkPauseRun(window_main,keyboard,nFrame);
    }
    return nFrame;
}

///*
///Create FG Model Image - Since target objects can be/will be are moving from the 1st frame, we need a statistical model
/// of the BG precalculated
///
unsigned int getBGModelFromVideo(cv::Mat& fgMask,MainWindow& window_main,QString videoFilename,QString outFileCSV,unsigned int startFrameCount)
{
        unsigned int nFrame         = startFrameCount; //Current Frame Number

        //create the capture object
        cv::VideoCapture capture(videoFilename.toStdString());
        if(!capture.isOpened())
        {
            //error in opening the video input
            std::cerr << "Unable to open video file: " << videoFilename.toStdString() << std::endl;
            std::exit(EXIT_FAILURE);
        }

        //read input data. ESC or 'q' for quitting
        while( !bExiting && (char)keyboard != 27 && nFrame <= MOGhistory)
        {
            //read the current frame
            if(!capture.read(frame))
            {
                if (nFrame == startFrameCount)
                {
                    std::cerr << "Unable to read first frame." << std::endl;
                    nFrame = 0; //Signals To caller that video could not be loaded.
                    exit(EXIT_FAILURE);
                }
                else
                {
                    std::cerr << "Unable to read next frame. So this video Is done." << std::endl;
                   std::cout << nFrame << " frames of Video processed. Move on to next timelapse video? " <<std::endl;
                  //  break;
                   continue;
               }
            }
            //Add frames from Last video
            nFrame = capture.get(CV_CAP_PROP_POS_FRAMES) + startFrameCount;

            /// Call Update BG Model ///
            updateBGFrame(frame,fgMask,nFrame);    //Hold A copy of Frame With all txt


            frame.copyTo(frameMasked);

            //cvb::CvBlobs blobs;
            //show the current frame and the fg masks
            cv::imshow(gstrwinName, frame);
            //window_main.showVideoFrame(frame,nFrame); //Show On QT Window

            cv::imshow(gstrwinName + " FG Mask", fgMask);
            //cv::imshow("FG Mask MOG", fgMaskMOG);
            //cv::imshow("FG Mask GMG ", fgMaskGMG);

           // if (!bTracking)
           //get the input from the keyboard
           keyboard = cv::waitKey( cFrameDelayms );


           checkPauseRun(window_main,keyboard,nFrame);


        } //main While loop
        //delete capture object
        capture.release();

        //delete kernel;
        //delete kernelClose;


        std::cout << "Background Processing  loop. Finished" << std::endl;

        return nFrame;
}


void processFrame(cv::Mat& frame,cv::Mat& fgMask,cv::Mat& frameMasked, unsigned int nFrame)
{
    unsigned int nLarva         =  0;
    double dblRatioPxChanged    = 0.0;
    //For Morphological Filter
    ////cv::Size sz = cv::Size(3,3);
    frame.copyTo(inputframe); //Keep Original Before Painting anything on it
    //update the background model
    //OPEN CV 2.4
    dLearningRate = 0.0;
//    cv::cvtColor( frame, fgMask, cv::COLOR_BGR2GRAY );
//    cv::threshold( fgMask, fgMask, g_BGthresh, 255, cv::THRESH_BINARY );
    pMOG2->apply(frame, fgMask,dLearningRate);
    //pKNN->apply(frame, fgMask,dLearningRate);

    //pMOG->apply(frame, fgMaskMOG,dLearningRate);
    //pGMG->apply(frame,fgMaskGMG,dLearningRate);
    //OPENCV 3
//        pMOG->operator()(frame, fgMaskMOG2,dLearningRate);
    //get the frame number and write it on the current frame
    //erode to get rid to food marks
    cv::erode(fgMask,fgMask,kernelOpen, cv::Point(-1,-1),1);
    //cv::dilate(fgMaskMOG2,fgMaskMOG2,kernel, cv::Point(-1,-1),4);
    //Apply Open Operation dilate(erode())
    cv::morphologyEx(fgMask,fgMask, cv::MORPH_OPEN, kernelOpen,cv::Point(-1,-1),1);

    //Do Close : erode(dilate())
    cv::morphologyEx(fgMask,fgMask, cv::MORPH_CLOSE, kernelClose,cv::Point(-1,-1),5);


    //Put Info TextOn Frame
    //Frame Number
    std::stringstream ss;
    cv::rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
              cv::Scalar(255,255,255), -1);
    ss << nFrame;
    std::string frameNumberString = ss.str();
    cv::putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    //Count on Original Frame
    std::stringstream strCount;
    strCount << "N:" << (nLarva);
    cv::rectangle(frame, cv::Point(10, 25), cv::Point(100,45), cv::Scalar(255,255,255), -1);
    cv::putText(frame, strCount.str(), cv::Point(15, 38),
            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    char buff[100];
    //Learning Rate
    //std::stringstream strLearningRate;
    std::sprintf(buff,"dL: %0.4f",dLearningRate);
    //strLearningRate << "dL:" << (double)(dLearningRate);
    cv::rectangle(frame, cv::Point(10, 50), cv::Point(100,70), cv::Scalar(255,255,255), -1);
    cv::putText(frame, buff, cv::Point(15, 63),
            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    //Time Rate - conv from ms to minutes

    std::sprintf(buff,"t: %0.2f",gTimer.elapsed()/(1000.0*60.0) );
    //strTimeElapsed << "" <<  << " m";
    cv::rectangle(frame, cv::Point(10, 75), cv::Point(100,95), cv::Scalar(255,255,255), -1);
    cv::putText(frame, buff, cv::Point(15, 88),
            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    //Count Fg Pixels // Ratio
    std::stringstream strFGPxRatio;
    dblRatioPxChanged = (double)cv::countNonZero(fgMask)/(double)fgMask.size().area();
    strFGPxRatio << "Dpx:" <<  dblRatioPxChanged;
    cv::rectangle(frame, cv::Point(10, 100), cv::Point(100,120), cv::Scalar(255,255,255), -1);
    cv::putText(frame, strFGPxRatio.str(), cv::Point(15, 113),
            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));


    //DRAW ROI RECT
    //cv::rectangle(frame,roi,cv::Scalar(50,250,50));
    drawROI();


    //cvb::CvBlobs blobs;
    if (bTracking)
    {
        //Simple Solution was to Use Contours To measure Larvae
        //countObjectsviaContours(fgMaskMOG2); //But not as efficient

       // cvb::CvBlobs blobs;
        nLarva = countObjectsviaBlobs(fgMask, blobs,tracks,gstroutDirCSV,frameNumberString,dMeanBlobArea);

        //ROI with TRACKs Fails
        const int inactiveFrameCount = 1000; //Number of frames inactive until track is deleted
        const int thActive = 0;// If a track becomes inactive but it has been active less than thActive frames, the track will be deleted.

        //Tracking has Bugs when it involves Setting A ROI. SEG-FAULTS
        //thDistance = 22 //Distance from Blob to track
        int thDistance = 60;
        cvb::cvUpdateTracks(blobs,tracks,vRoi, thDistance, inactiveFrameCount,thActive);
        //saveTracks(tracks,trkoutFileCSV,frameNumberString);

        cvb::cvRenderTracks(tracks, &frameImg, &frameImg,CV_TRACK_RENDER_ID | CV_TRACK_RENDER_PATH,&trackFnt);

        /// Get Fish Only Image ///
        framefishMasked = cv::Mat::zeros(frame.rows, frame.cols,CV_8U);
//      frameImg = frameMasked;
//      IplImage fgMaskImg =  fgMask;
//      labelImg=cvCreateImage(cvGetSize(&frameImg), IPL_DEPTH_LABEL, 1);
//      cvb::cvLabel( &fgMaskImg, labelImg, blobs );
//      cvb::cvRenderBlob(labelImg, fishBlob, &frameImg, &frameImg,  CV_BLOB_RENDER_CENTROID|CV_BLOB_RENDER_BOUNDING_BOX , cv::Scalar(200,200,200),1);
//      frame.copyTo(frameMasked,fgMask);
        //frameMasked = cv::Mat::zeros(frame.rows, frame.cols,CV_8U); //Forget
        /// Add Picture frame to Enhance Contrast
        ///Do Slow Forgetting of image - To Enhance Features-Add motion Blur
        //g(x) = alpha * f(x) + beta
        //framefishMasked.convertTo(framefishMasked, -1, 0.40, 0); //decrease contrast (1/3)

        /// \TODO optimize this. pic is Gray Scale Originally anyway
        cv::cvtColor( fgMaskFish, fgMaskFish, cv::COLOR_BGR2GRAY );
        //cv::dilate(fgMaskFish,fgMaskFish,kernelOpen, cv::Point(-1,-1),4); //
        inputframe.copyTo(framefishMasked,fgMaskFish );
        detectZfishFeatures(framefishMasked);

    }


}
///
/// \brief updateBGFrame Update BG model for a fixed number of frames
/// \param frame
/// \param fgMask
/// \param nFrame
/// \return returns false when limit of updates is reached
///
bool updateBGFrame(cv::Mat& frame, cv::Mat& fgMask, unsigned int nFrame)
{

    bool ret = true;
    //Speed that stationary objects are removed
    double dblRatioPxChanged    = 0.0;

    //update the background model
    //OPEN CV 2.4
    if (nFrame > MOGhistory)
    {
        dLearningRate =0.0;
        ret = false;
    }
    dblRatioPxChanged = (double)cv::countNonZero(fgMask)/(double)fgMask.size().area();

    pMOG2->apply(frame, fgMask,dLearningRate);
    //pKNN->apply(frame, fgMask,dLearningRate);


    //pMOG->apply(frame, fgMaskMOG,dLearningRate);
    //pGMG->apply(frame,fgMaskGMG,dLearningRate);



        //OPENCV 3 MORPHOLOGICAL
    //get the frame number and write it on the current frame
    //erode to get rid to food marks
    //cv::erode(fgMaskMOG2,fgMaskMOG2,kernel, cv::Point(-1,-1),3);
    //Do Close : erode(dilate())
    //cv::morphologyEx(fgMaskMOG2,fgMaskMOG2, cv::MORPH_CLOSE, kernelClose,cv::Point(-1,-1),2);
    //cv::dilate(fgMaskMOG2,fgMaskMOG2,kernel, cv::Point(-1,-1),4);
    //Apply Open Operation dilate(erode())
    //cv::morphologyEx(fgMaskMOG2,fgMaskMOG2, cv::MORPH_OPEN, kernel,cv::Point(-1,-1),2);


//    //Put Info TextOn Frame
//    //Frame Number
//    std::stringstream ss;
//    cv::rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
//              cv::Scalar(255,255,255), -1);
//    ss << nFrame;
//    std::string frameNumberString = ss.str();
//    cv::putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
//            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

//    //Count on Original Frame
//    std::stringstream strCount;
//    strCount << "N:" << (nLarva);
//    cv::rectangle(frame, cv::Point(10, 25), cv::Point(100,45), cv::Scalar(255,255,255), -1);
//    cv::putText(frame, strCount.str(), cv::Point(15, 38),
//            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

//    char buff[100];
//    //Learning Rate
//    //std::stringstream strLearningRate;
//    std::sprintf(buff,"dL: %0.4f",dLearningRate);
//    //strLearningRate << "dL:" << (double)(dLearningRate);
//    cv::rectangle(frame, cv::Point(10, 50), cv::Point(100,70), cv::Scalar(255,255,255), -1);
//    cv::putText(frame, buff, cv::Point(15, 63),
//            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));


//    //Time Rate - conv from ms to minutes //TODO: Replace With actual framerate
//    std::sprintf(buff,"t: %0.2fs",nFrame/55.0 );
//    //strTimeElapsed << "" <<  << " m";
//    cv::rectangle(frame, cv::Point(10, 75), cv::Point(100,95), cv::Scalar(255,255,255), -1);
//    cv::putText(frame, buff, cv::Point(15, 88),
//            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    //Count Fg Pixels // Ratio
    std::stringstream strFGPxRatio;
    dblRatioPxChanged = (double)cv::countNonZero(fgMask)/(double)fgMask.size().area();
    strFGPxRatio << "Dpx:" <<  dblRatioPxChanged;
    cv::rectangle(frame, cv::Point(10, 100), cv::Point(100,120), cv::Scalar(255,255,255), -1);
    cv::putText(frame, strFGPxRatio.str(), cv::Point(15, 113),
            cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    return ret; //If False then tell calling function to stop updating
}



//
// Process Larva video, removing BG, detecting moving larva- Setting the learning rate will change the time required
// to remove a pupa from the scene -
//
unsigned int processVideo(cv::Mat& fgMask, MainWindow& window_main, QString videoFilename, QString outFileCSV, unsigned int startFrameCount)
{

    //Speed that stationary objects are removed

    unsigned int nFrame = startFrameCount; //Current Frame Number

    bPaused =true; //Start Paused

    std::string frameNumberString;

    //?Replicate FG Mask to method specific
    //fgMask.copyTo(fgMaskMOG2);
    //fgMask.copyTo(fgMaskMOG);
    //fgMask.copyTo(fgMaskGMG);


    //Make Variation of FileNames for other Output

    QString trkoutFileCSV = outFileCSV;
    trkoutFileCSV.truncate(trkoutFileCSV.lastIndexOf("."));
    trkoutFileCSV.append("_tracks.csv");
    QString vialcountFileCSV = outFileCSV;
    vialcountFileCSV.truncate(vialcountFileCSV.lastIndexOf("."));
    vialcountFileCSV.append("_N.csv");

    //REPORT
   std::cout << "Tracking data saved to :" << vialcountFileCSV.toStdString()  <<std::endl;
   std::cout << "\t " << outFileCSV.toStdString() <<std::endl;
   std::cout << "\t " << trkoutFileCSV.toStdString()  <<std::endl;




    //create the capture object
    cv::VideoCapture capture(videoFilename.toStdString());
    if(!capture.isOpened())
    {
        //error in opening the video input
        std::cerr << "Unable to open video file: " << videoFilename.toStdString() << std::endl;
        std::exit(EXIT_FAILURE);
    }




    //read input data. ESC or 'q' for quitting
    while( !bExiting && (char)keyboard != 27 )
    {
        //read the current frame
        if(!capture.read(frame))
        {
            if (nFrame == startFrameCount)
            {
                std::cerr << "Unable to read first frame." << std::endl;
                nFrame = 0; //Signals To caller that video could not be loaded.
                exit(EXIT_FAILURE);
            }
            else
            {
               std::cerr << "Unable to read next frame. So this video Is done." << std::endl;
               std::cout << nFrame << " frames of Video processed. Move on to next timelapse video? " <<std::endl;
                ::saveImage(frameNumberString,gstroutDirCSV,frameMasked);
               //continue;
               break;
           }
        }



        //Add frames from Last video
        nFrame = capture.get(CV_CAP_PROP_POS_FRAMES) + startFrameCount;

        //Make Global Roi on 1st frame
        if (nFrame == 1)
        {
            //Add Global Roi
            ltROI newROI(cv::Point(frame.cols/2,frame.rows/2),cv::Point(0,0));
            addROI(newROI);
        }




        frameMasked = cv::Mat::zeros(frame.rows, frame.cols,CV_8U);
        frame.copyTo(frameMasked,fgMask);



        processFrame(frame,fgMask,frameMasked,nFrame);
        //show the current frame and the fg masks
        cv::imshow(gstrwinName + " FishOnly",frameMasked);

        window_main.showVideoFrame(frame,nFrame); //Show On QT Window

        if (showMask)
        {
            cv::imshow(gstrwinName + " FG Mask", fgMask);
            cv::imshow(gstrwinName + " FG Fish Mask", fgMaskFish);
        }


        if (bTracking)
            saveTracks(tracks,trkoutFileCSV,frameNumberString);

        keyboard = cv::waitKey( cFrameDelayms );
        checkPauseRun(window_main,keyboard,nFrame);


    } //main While loop
    //delete capture object
    capture.release();



    std::cout << "Exiting video processing loop." <<std::endl;

    return nFrame;
}




void checkPauseRun(MainWindow& win, int& keyboard,unsigned int nFrame)
{
    //implemend Pause
    if ((char)keyboard == 'p')
    {
        //frame.copyTo(frameCpy);
        bPaused = true;
    }

    if ((char)keyboard == 'q')
    {
        bExiting = true;
    }

    //Make Frame rate faster
    if ((char)keyboard == '+')
        cFrameDelayms--;
    //Slower
    if ((char)keyboard == '-')
        cFrameDelayms++;




    if ((char)keyboard == 't') //Toggle Tracking
        bTracking = !bTracking;

        while (bPaused && !bExiting)
        {
            int ms = 20;
            struct timespec ts = { ms / 1000, (ms % 1000) * 1000 * 1000 };
            nanosleep(&ts, NULL);
            //Wait Until Key to unpause is pressed
            keyboard = cv::waitKey( 30 );

            if ((char)keyboard == 's')
            {
                bSaveImages = !bSaveImages;
                std::stringstream frameNumberString; frameNumberString << nFrame;

                ::saveImage(frameNumberString.str(),gstroutDirCSV,frame);
            }

            if ((char)keyboard == 'r')
            {
                bPaused = false;
                gTimer.start();
            }

            //Toggle Show the masked - where blob id really happens
            if ((char)keyboard == 'm')
                 showMask = !showMask;

            if ((char)keyboard == 'q')
                bExiting = true; //Main Loop Will handle this
                 //break;


            //if ((char)keyboard == 'c')
            if (nFrame > 1)
            {
              //  cv::imshow(gstrwinName, frame);
               win.showCVimg(frame); //Show On QT Window
            }

        }


    //Toggle Show the masked - where blob id really happens
    if ((char)keyboard == 'm')
             showMask = !showMask;
}

bool saveImage(std::string frameNumberString,QString dirToSave,cv::Mat& img)
{

    //Save Output BG Masks
    QString imageToSave =   QString::fromStdString( std::string("output_MOG_") + frameNumberString + std::string(".png"));
    //QString dirToSave = qApp->applicationDirPath();

    dirToSave.append("/pics/");
    imageToSave.prepend(dirToSave);

    if (!QDir(dirToSave).exists())
    {
        std::cerr << "Make directory " << dirToSave.toStdString() << std::endl;
        QDir().mkpath(dirToSave);
    }

    bool saved = cv::imwrite(imageToSave.toStdString(), img);
    if(!saved) {
        cv::putText(img,"Failed to Save " + imageToSave.toStdString(), cv::Point(25, 25), cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(250,250,250));
        cv::putText(img,"Failed to Save" + imageToSave.toStdString(), cv::Point(25, 25), cv::FONT_HERSHEY_SIMPLEX, 0.4 , cv::Scalar(0,0,0));
       std::cerr << "Unable to save " << imageToSave.toStdString() << std::endl;
        return false;
    }
    else
    {
     std::cout << "Saved image " << imageToSave.toStdString() <<std::endl;
    }

    //cv::imshow("Saved Frame", img);

    return true;
}

int countObjectsviaContours(cv::Mat& srcimg )
{
     cv::Mat imgTraced;
     srcimg.copyTo(imgTraced);
     std::vector< std::vector <cv::Point> > contours; // Vector for storing contour
     std::vector< cv::Vec4i > hierarchy;

     cv::findContours( imgTraced, contours, hierarchy,CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE ); // Find the contours in the image
     for( unsigned int i = 0; i< contours.size(); i=hierarchy[i][0] ) // iterate through each contour.
     {
          cv::Rect r= cv::boundingRect(contours[i]);
          cv::rectangle(imgTraced,r, cv::Scalar(255,0,0),1,8,0);
          cv::rectangle(frame,r, cv::Scalar(255,0,0),1,8,0);
     }

     //Write text For Count on Original Frame
     std::stringstream strCount;
     strCount << "N:" << ((int)contours.size());

     cv::rectangle(frame, cv::Point(540, 2), cv::Point(690,20), cv::Scalar(255,255,255), -1);
     cv::putText(frame, strCount.str(), cv::Point(545, 15),
             cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    std::cout << " Larvae  "<< strCount.str() << std::endl;
    //imshow("Contoured Image",frame);


    // To get rid of the smaller object and the outer rectangle created
      //because of the additional mask image we enforce a lower limit on area
      //to remove noise and an upper limit to remove the outer border.

 /* if (contourArea(contours_poly[i])>(mask.rows*mask.cols/10000) && contourArea(contours_poly[i])<mask.rows*mask.cols*0.9){
      boundRect[i] = boundingRect( Mat(contours_poly[i]) );
      minEnclosingCircle( (Mat)contours_poly[i], center[i], radius[i] );
      circle(drawing,center[i], (int)radius[i], Scalar(255,255,255), 2, 8, 0);
      rectangle(drawing,boundRect[i], Scalar(255,255,255),2,8,0);
      num_object++;
}
      */

    return contours.size();
}


int countObjectsviaBlobs(cv::Mat& srcimg,cvb::CvBlobs& blobs,cvb::CvTracks& tracks,QString outDirCSV,std::string& frameNumberString,double& dMeanBlobArea)
{

    ///// Finding the blobs ////////
     int cnt = 0;
     uint minBlobArea = 0;
     uint maxBlobArea = 0;


     IplImage fgMaskImg;
///  REGION OF INTEREST - UPDATE - SET
     frameImg           =  frame; //Convert The Global frame to lplImage
     fgMaskFish         = cv::Mat::zeros(frame.rows, frame.cols,CV_8UC3); //Empty Canvas For Just Fish Blob
     framefishMaskImg   = fgMaskFish; //Copy over so as to use legacy lpimg pointer
     fgMaskImg          =  srcimg;

    if (bROIChanged || ptROI2.x != 0)
    {
        //Set fLAG sO FROM now on Region of interest is used and cannot be changed.
        bROIChanged = true;
    }


   //std::cout << "Roi Sz:" << vRoi.size() <<std::endl;
    labelImg=cvCreateImage(cvGetSize(&frameImg), IPL_DEPTH_LABEL, 1);
    cvb::cvLabel( &fgMaskImg, labelImg, blobs );

    cvb::cvFilterByROI(vRoi,blobs); //Remove Blobs Outside ROIs

    cvb::cvBlobAreaStat(blobs,dMeanBlobArea,dVarBlobArea,maxBlobArea,minBlobArea);
    double dsigma = 1.0*std::sqrt(dVarBlobArea);

    //Separate Fish
    //copy blobs and then Filter to separate classes

    //Allow only Fish Area Through
    fishblobs = cvb::cvFilterByArea(blobs,std::max(dMeanBlobArea,(double)thresh_fishblobarea),maxBlobArea+dsigma,CV_RGB(0,10,120) ); //Remove Small Blobs
    //Remove Fish
    foodblobs = cvb::cvFilterByArea(blobs,std::max(minBlobArea-dsigma,4.0),(unsigned int)std::max((dMeanBlobArea+dsigma),maxBlobArea/4.0),CV_RGB(0,200,0)); //Remove Large Blobs



    //                  (CvBlobs &blobs,unsigned int minArea, unsigned int maxArea)


    //Debug Show Mean Size Var
    //std::cout << dMeanBlobArea <<  " " << dMeanBlobArea+3*sqrt(dVarBlobArea) <<std::endl;
    unsigned int RoiID = 0;
    for (std::vector<ltROI>::iterator it = vRoi.begin(); it != vRoi.end(); ++it)
    {
        ltROI iroi = (ltROI)(*it);
        RoiID++;

        //Custom Filtering the blobs for Rendering
        //Count Blobs in ROI
        //Find Fish

        //cvb::CvBlob* fishBlob = cvb::cvLargestBlob(blobs);
        //RENDER FISH
        for (cvb::CvBlobs::const_iterator it = fishblobs.begin(); it!=fishblobs.end(); ++it)
        {
            cvb::CvBlob* blob = it->second;
            cv::Point pnt;
            pnt.x = blob->centroid.x;
            pnt.y = blob->centroid.y;

            if (iroi.contains(pnt))
            {
                //Render Paramecium
                //cnt++; //CV_BLOB_RENDER_COLOR
                    cvb::cvRenderBlob(labelImg, blob, &fgMaskImg, &framefishMaskImg, CV_BLOB_RENDER_COLOR | CV_BLOB_RENDER_CENTROID, CV_RGB(150,150,150),1);
                    //Make a mask to Surround the fish - So as to overcome BG Substraction Loses - by redecting countour
                    cv::circle(fgMaskFish,cv::Point(blob->centroid.x,blob->centroid.y),160,CV_RGB(255,255,255),-1);
            }
        }

        //Now Render Food
        for (cvb::CvBlobs::const_iterator it = foodblobs.begin(); it!=foodblobs.end(); ++it)
        {
            cvb::CvBlob* blob = it->second;
            cv::Point pnt;
            pnt.x = blob->centroid.x;
            pnt.y = blob->centroid.y;

            if (iroi.contains(pnt))
            {
                    cvb::cvRenderBlob(labelImg, blob, &fgMaskImg, &frameImg, CV_BLOB_RENDER_CENTROID|CV_BLOB_RENDER_BOUNDING_BOX ,CV_RGB(0,200,0),0.4);
            }
        }



///Deprecated Render Tracks - > There is a Custom Render Tracks in ROI Loop
//        for (cvb::CvTracks::const_iterator it=tracks.begin(); it!=tracks.end(); ++it)
//        {
//            cv::Point pnt;
//            pnt.x = it->second->centroid.x;
//            pnt.y = it->second->centroid.y;
//            //if (iroi.contains(pnt))
//               // cvRenderTrack(*((*it).second) ,it->first ,  &fgMaskImg, &frameImg, CV_TRACK_RENDER_ID | CV_TRACK_RENDER_PATH,&trackFnt );
//        }

        //cvSetImageROI(&frameImg, iroi);
        //cvSetImageROI(&fgMaskImg, iroi);
        //cvSetImageROI(labelImg,iroi);
        // render blobs in original image
        //cvb::cvRenderBlobs( labelImg, blobs, &fgMaskImg, &frameImg,CV_BLOB_RENDER_CENTROID|CV_BLOB_RENDER_BOUNDING_BOX | CV_BLOB_RENDER_COLOR);

        //Make File Names For Depending on the Vial - Crude but does the  job
        QString strroiFileN = outDirCSV;
        QString strroiFilePos = outDirCSV;
        char buff[150];
        sprintf(buff,"/V%d_pos_N.csv",RoiID);
        strroiFileN.append(buff);
        sprintf(buff,"/V%d_pos.csv",RoiID);
        strroiFilePos.append(buff);

        saveTrackedBlobs(blobs,strroiFilePos,frameNumberString,iroi);
        cnt += saveTrackedBlobsTotals(blobs,tracks,strroiFileN,frameNumberString,iroi);
    } //For Each ROI

    //Save to Disk
    if (bTracking && bSaveImages)
    {
        saveImage(frameNumberString,outDirCSV,frame);
        cv::putText(frame, "Save ON", cv::Point(15, 600),
                cv::FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

    }



    // *always* remember freeing unused IplImages
    cvReleaseImage( &labelImg );

    return cnt;
}

int saveTrackedBlobs(cvb::CvBlobs& blobs,QString filename,std::string frameNumber,ltROI& roi)
{
    int cnt = 0;
    int Vcnt = 1;
    bool bNewFileFlag = true;

    //Loop Over ROI
    Vcnt++; //Vial Count
    cnt = 0;

    QFile data(filename);
    if (data.exists())
        bNewFileFlag = false;

    if(data.open(QFile::WriteOnly |QFile::Append))
    {
        QTextStream output(&data);
        if (bNewFileFlag)
             output << "frameN,SerialN,BlobLabel,Centroid_X,Centroid_Y,Area\n" ;

        //Loop Over Blobs
        for (cvb::CvBlobs::const_iterator it=blobs.begin(); it!=blobs.end(); ++it)
        {

            cvb::CvBlob* cvB = it->second;
            cv::Point pnt;
            pnt.x = cvB->centroid.x;
            pnt.y = cvB->centroid.y;

            cnt++;

            if (roi.contains(pnt))
                //Printing the position information
                output << frameNumber.c_str() << "," << cnt <<","<< cvB->label << "," << cvB->centroid.x <<","<< cvB->centroid.y  <<","<< cvB->area  <<"\n";
          }


       data.close();

      }


    return cnt;
}

//Saves the total Number of Counted Blobs and Tracks only
int saveTrackedBlobsTotals(cvb::CvBlobs& blobs,cvb::CvTracks& tracks,QString filename,std::string frameNumber,ltROI& roi)
{

    bool bNewFileFlag = true;
    int cnt = 0;
    int Larvacnt = 0;
    cnt++;
    //cv::Rect iroi = (cv::Rect)(*it);

    QFile data(filename);
    if (data.exists())
        bNewFileFlag = false;

    if(data.open(QFile::WriteOnly |QFile::Append))
    {

        int blobCount = 0;
        int trackCount = 0;

        //Count Blobs in ROI
        for (cvb::CvBlobs::const_iterator it = blobs.begin(); it!=blobs.end(); ++it)
        {
            cvb::CvBlob* blob = it->second;
            cv::Point pnt;
            pnt.x = blob->centroid.x;
            pnt.y = blob->centroid.y;

            if (roi.contains(pnt))
                blobCount++;
        }

        //Count Tracks in ROI
        for (cvb::CvTracks::const_iterator it = tracks.begin(); it!=tracks.end(); ++it)
        {
            cvb::CvTrack* track = it->second;
            cv::Point pnt;
            pnt.x = track->centroid.x;
            pnt.y = track->centroid.y;

            if (roi.contains(pnt))
                trackCount++;
        }


        QTextStream output(&data);
        if (bNewFileFlag)
             output << "frameN,blobN,TracksN \n";

        output << frameNumber.c_str() << "," << blobCount << "," << trackCount <<"\n";
        Larvacnt +=blobCount;
        data.close();
    }


    return Larvacnt;
}


//std::vector<cvb::CvBlob*> getBlobsinROI(cvb::CvBlobs& blobs)
//{
    //std::vector<cvb::CvBlob*> *vfiltBlobs = new std::vector<cvb::CvBlob*>((blobs.size()));

   // return 0;

//}


ltROI* ltGetFirstROIContainingPoint(ltROIlist& vRoi ,cv::Point pnt)
{
    for (ltROIlist::iterator it = vRoi.begin(); it != vRoi.end(); ++it)
    {
        ltROI* iroi = &(*it);
        if (iroi->contains(pnt))
                return iroi;
    }

    return 0; //Couldn't find it
}


int saveTracks(cvb::CvTracks& tracks,QString filename,std::string frameNumber)
{
    bool bNewFileFlag = true;
    int cnt;
    int Vcnt = 0;

    //Loop Over ROI
    for (ltROIlist::iterator it = vRoi.begin(); it != vRoi.end(); ++it)
    {
        cnt = 1;
        Vcnt++;
        ltROI iroi = (ltROI)(*it);
        QString strroiFile = filename.left(filename.lastIndexOf("/"));
        char buff[50];
        sprintf(buff,"/V%d_pos_tracks.csv",Vcnt);
        strroiFile.append(buff);

        QFile data(strroiFile);
        if (data.exists())
            bNewFileFlag = false;



        if(data.open(QFile::WriteOnly |QFile::Append))
        {

            QTextStream output(&data);
            if (bNewFileFlag)
                 output << "frameN,TrackID,TrackBlobLabel,Centroid_X,Centroid_Y,Lifetime,Active,Inactive\n";

            //Save Tracks In ROI
            for (cvb::CvTracks::const_iterator it=tracks.begin(); it!=tracks.end(); ++it)
            {
                cnt++;
                cvb::CvTrack* cvT = it->second;
                //cvb::CvLabel cvL = it->first;

                cv::Point pnt;
                pnt.x = cvT->centroid.x;
                pnt.y = cvT->centroid.y;

                if (iroi.contains(pnt))
                    //Printing the position information +
                    //+ lifetime; ///< Indicates how much frames the object has been in scene.
                    //+active; ///< Indicates number of frames that has been active from last inactive period.
                    //+ inactive; ///< Indicates number of frames that has been missing.
                    output << frameNumber.c_str()  << "," << cvT->id  << "," << cvT->label  << "," << cvT->centroid.x << "," << cvT->centroid.y << "," << cvT->lifetime  << "," << cvT->active  << "," << cvT->inactive <<"\n";
              }
            }
        data.close();

   } //Loop ROI
     return cnt;
}
//Mouse Call Back Function
void CallBackFunc(int event, int x, int y, int flags, void* userdata)
{
     if  ( event == cv::EVENT_LBUTTONDOWN )
     {
        bMouseLButtonDown = true;
         //ROI is locked once tracking begins
        if (bPaused && !bROIChanged) //CHANGE ROI Only when Paused and ONCE
        { //Change 1st Point if not set or If 2nd one has been set
             if ( b1stPointSet == false)
             {
                ptROI1.x = x;
                ptROI1.y = y;
                cv::circle(frame,ptROI1,3,cv::Scalar(255,0,0),1);

                b1stPointSet = true;
             }
             else //Second & Final Point
             {
                ptROI2.x = x;
                ptROI2.y = y;
                ltROI newROI(ptROI1,ptROI2);
                //roi = newROI;

                addROI(newROI);
                drawROI();
                b1stPointSet = false; //Rotate To 1st Point Again
             }
        }


        std::cout << "Left button of the mouse is clicked - position (" << x << ", " << y << ")" <<std::endl;
     }

     if (event == cv::EVENT_LBUTTONUP)
     {
        bMouseLButtonDown = false;
     }
     else if  ( event == cv::EVENT_RBUTTONDOWN )
     {
        cv::Point mousepnt;
        mousepnt.x = x;
        mousepnt.y = y;
       std::cout << "Right button of the mouse is clicked - Delete ROI position (" << x << ", " << y << ")" <<std::endl;

        if (bPaused && !bROIChanged)
        {
            deleteROI(mousepnt);
            drawROI();
        }
     }
     else if  ( event == cv::EVENT_MBUTTONDOWN )
     {
         std::cout << "Middle button of the mouse is clicked - position (" << x << ", " << y << ")" <<std::endl;
     }
     else if ( event == cv::EVENT_MOUSEMOVE )
     {
         //std::cout << "Mouse move over the window - position (" << x << ", " << y << ")" <<std::endl;

     }
}

void addROI(ltROI& newRoi)
{
    //std::vector<cv::Rect>::iterator it= vRoi.end();
    //vRoi.insert(it,newRoi);
    vRoi.push_back(newRoi);
    //Draw the 2 points
    cv::circle(frame,ptROI1,3,cv::Scalar(255,0,0),1);
    cv::circle(frame,ptROI2,3,cv::Scalar(255,0,0),1);

   std::cout << "Added, total:" << vRoi.size() <<std::endl;

}

void deleteROI(cv::Point mousePos)
{
    std::vector<ltROI>::iterator it = vRoi.begin();

    while(it != vRoi.end())
    {
        ltROI* roi=&(*it);

        if (roi->contains(mousePos))
        {
            std::vector<ltROI>::iterator tmp = it;
            vRoi.erase(tmp);
           std::cout << "Deleted:" << roi->x() << " " << roi->y() <<std::endl;
            break;
        }
         ++it;

    }

}

void drawROI()
{
    //frameCpy.copyTo(frame); //Restore Original IMage
    for (std::vector<ltROI>::iterator it = vRoi.begin(); it != vRoi.end(); ++it) {

        ltROI iroi = (ltROI)(*it);
         //cv::rectangle(frame,iroi,cv::Scalar(0,0,250));
         cv::circle(frame,cv::Point(iroi.x() ,iroi.y()),iroi.radius,cv::Scalar(0,0,250),2);

         if (bTracking)
         {
             cv::Point pt1,pt2;
             pt1.x = iroi.centre.x;
             pt1.y = iroi.centre.y;
             pt2.x = pt1.x + iroi.radius;
             pt2.y = pt1.y; //+ iroi.height;

             cv::circle(frame,pt1,3,cv::Scalar(255,0,0),1);
             cv::circle(frame,pt2,3,cv::Scalar(255,0,0),1);


         }
    }
}

///
/// \brief detectZfishFeatures - Used to create geometric representations of main zebrafish Features : Eyes, Body, tail
/// these are saved as point arrays on which angles and other measurements can be obtained
/// \param maskedGrayImg - IMage Masked so only fish is being shown Showing
/// \return
///
void detectZfishFeatures(cv::Mat& maskedImg)
{


    int max_thresh = 255;
    cv::RNG rng(12345);

    cv::Mat threshold_output,threshold_output_H, threshold_output_COMB, maskedImg_gray,maskedfishImg_gray;
    cv::Mat maskfishFeature,maskedfishFeature;

    cv::Mat grad,grad_x, grad_y;
    cv::Mat framelapl;
    std::vector<std::vector<cv::Point> > contours_body;
    std::vector<cv::Vec4i> hierarchy_body;
    std::vector<std::vector<cv::Point> > contours_laplace;
    std::vector<cv::Vec4i> hierarchy_laplace; //Contour Relationships  [Next, Previous, First_Child, Parent]


    /// Convert image to gray and blur it
    cv::cvtColor( maskedImg, maskedImg_gray, cv::COLOR_BGR2GRAY );
    cv::blur( maskedImg_gray, maskedImg_gray, cv::Size(3,3) );

    /// Detect edges using Threshold
    cv::threshold( maskedImg_gray, threshold_output, g_Segthresh, max_thresh, cv::THRESH_BINARY ); //Log Threshold Image


    //qDebug() << g_Segthresh;

    ////maskedImg_gray.convertTo(maskedImg_gray, -1, (double)g_Segthresh/10.0, 0); //increase the contrast (double) //cv::ADAPTIVE_THRESH_MEAN_C
    //cv::adaptiveThreshold( maskedImg_gray, threshold_output, 250,  cv::ADAPTIVE_THRESH_MEAN_C,cv::THRESH_BINARY,g_Segthresh,0   );

    //Segment Features dilate(erode())
    //cv::morphologyEx(threshold_output,threshold_output, cv::MORPH_OPEN, kernelOpenfish,cv::Point(-1,-1),12);
    //cv::erode(threshold_output,threshold_output,kernelOpenfish, cv::Point(-1,-1),16);

    //Remove Speckles
    cv::filterSpeckles(threshold_output,0,3.0*dMeanBlobArea,20 );
    //maskedImg_gray.copyTo(threshold_output_H,threshold_output); //Copy Fish Only Mask
    // Increase  Threshold on FishImage (Fish Only masked) to detect Body Structure
    //cv::threshold( threshold_output_H, threshold_output_H, g_Segthresh*5, max_thresh, cv::THRESH_BINARY ); //High threshold - Used to detect body
    cv::morphologyEx(threshold_output,threshold_output_H, cv::MORPH_OPEN, kernelOpenfish,cv::Point(-1,-1),2);
    cv::erode(threshold_output_H,threshold_output_H,kernelOpenfish,cv::Point(-1,-1),4);


    cv::bitwise_xor(threshold_output,threshold_output_H,threshold_output_COMB);
   // maskedImg_gray.convertTo(maskedImg_gray,CV_16SC1);
    //threshold_output.convertTo(threshold_output, CV_16SC1);
    //threshold_output = cv::abs(threshold_output);
    //threshold_output.convertTo(threshold_output, CV_8UC1);

    cv::dilate(threshold_output,threshold_output,kernelOpenfish,cv::Point(-1,-1),2);
    maskedImg_gray.copyTo(maskedfishImg_gray,threshold_output); //Mask The Laplacian
    cv::Laplacian(maskedfishImg_gray,framelapl,CV_8UC1,g_BGthresh);
    //cv::dilate(framelapl,framelapl,kernelOpen,cv::Point(-1,-1),2);
    //dilate(erode())
    cv::morphologyEx(framelapl,framelapl, cv::MORPH_CLOSE, kernelOpenLaplace,cv::Point(-1,-1),4);

    ///Edge DEtection Using SOBEL
    //cv::Sobel(maskedImg_gray,grad_x,CV_16SC1,1,0); //,CV_SCHARR
    //cv::convertScaleAbs(grad_x, grad_x );
    //cv::Sobel(maskedImg_gray,grad_y,CV_16SC1,0,1); //,CV_SCHARR
    //cv::convertScaleAbs(grad_y, grad_y );

    /// Total Gradient (approximate)
     //cv::addWeighted( grad_x, 0.5, grad_y, 0.5, 0, grad );


    //cv::adaptiveThreshold( grad, threshold_output, 250,  cv::ADAPTIVE_THRESH_MEAN_C, cv::THRESH_BINARY,g_Segthresh,0   );
    //cv::threshold( framelapl, threshold_output, g_Segthresh, max_thresh, cv::THRESH_BINARY );
    //cv::cvtColor( threshold_output, threshold_output, cv::cvarrToMat());
    //cv::ui

    /// Find contours
    //cv::findContours( threshold_output, contours,hierarchy, cv::RETR_TREE,cv::CHAIN_APPROX_NONE , cv::Point(0, 0) ); //cv::CHAIN_APPROX_SIMPLE
    //cv::findContours( threshold_output, contours_full,hierarchy_full, cv::RETR_TREE,cv::CHAIN_APPROX_NONE , cv::Point(0, 0) ); //cv::CHAIN_APPROX_SIMPLE
    //Used RETR_CCOMP that only considers 1 level children hierachy - I use the 1st child to obtain the body contour of the fish
    cv::findContours( threshold_output_COMB, contours_body,hierarchy_body, cv::RETR_CCOMP,cv::CHAIN_APPROX_NONE , cv::Point(0, 0) ); //cv::CHAIN_APPROX_SIMPLE

    //cv::imshow("Edges Sobel",grad);
    //cv::imshow("Edges Laplace",framelapl);

    /// Find the convex hull object for each contour
    std::vector<std::vector<cv::Point> >hull( contours_body.size() );
    std::vector<std::vector<cv::Point2f> >triangle( contours_body.size() );
    //hull.resize(contours.size());
//    for( size_t i = 0; i < contours_full.size(); i++ )
//    {
        //Does it belong to Fish?

        //Is there an associated Body

  //  }

    //Clear Contours - And Associate

    cv::RotatedRect rectFeatures[contours_body.size()];

    //assert(contours_full.size() == contours_body.size());




    ///Iterate FISH list - Check If Contour belongs to any fish Otherwise ignore
    for (cvb::CvBlobs::const_iterator it = fishblobs.begin(); it!=fishblobs.end(); ++it)
    {
        fishModel sfish;
        maskfishFeature = cv::Mat::zeros(frameMasked.rows, frameMasked.cols,CV_8U); //Empty Canvas This fish's mask
        int idxblobContour;
        bool bContourfound =false;
        cvb::CvBlob* blob = it->second;
        cv::Point centroid(blob->centroid.x,blob->centroid.y);

         /// Render Only Countours that contain fish Blob centroid (Only Fish Countour)
        ///Search Through Contours - Draw contours + hull results
        for( size_t i = 0; i< contours_body.size(); i++ )
        {
         cv::Scalar colorFeature =  CV_RGB(150,10,10);
         //drawContours( drawing, contours, (int)i, color, 1, 8, vector<Vec4i>(), 0, Point() );

        ///Contour Filters
        //Check if this is Parent Contour Before Checking Polygon Test [Next, Previous, First_Child, Parent]
        /////Only Process Parent Contours
        if (hierarchy_body[i][3] != -1) // Need to have no parent
           continue;
        if (hierarchy_body[i][2] == -1)  // Need to have child
            continue;
        assert(hierarchy_body[hierarchy_body[i][2]][3] == i ); // check that the parent of the child is this contour i


        ///Check if Contour Belongs to fishBlob by Centroid Inclusion -
        /// Of Approximate Ellipse hull
        cv::convexHull( cv::Mat(contours_body[i]), hull[i], false );
        rectFeatures[i] = cv::fitEllipse(hull[i]);


        //check both contour and the Fitted Elipse for blob match that contour, as the blob centroid can fall outside contour
        if (!rectFeatures[i].boundingRect().contains(centroid))
                continue; //Too far - check Next Fish
        else
            idxblobContour = i;
            bContourfound = true;

        } //End For each Contour
        ///Search Again -attach to closest contour
        //In Not found Search Again By distance
        if (!bContourfound)
        {
            //Find Closest Contour
            int mindistToCentroid = 2000;
            for( size_t i = 0; i< contours_body.size(); i++ )
            {
                int distToCentroid = cv::pointPolygonTest(contours_body[i],centroid,true);
                if (distToCentroid < mindistToCentroid)
                {
                    if (hierarchy_body[i][3] != -1) // Need to have no parent
                       continue;
                    if (hierarchy_body[i][2] == -1)  // Need to have child
                        continue;

                    //Otherwise Keep As blob Contour
                    idxblobContour = i;
                    mindistToCentroid = distToCentroid;//New Min
                    bContourfound = true;
                }
            }
            std::cerr << "Closest Contour :" << idxblobContour << " d:" << mindistToCentroid << std::endl;
        }


        if (!bContourfound)
        {
            std::cerr << "Fish " << blob->label << " Contour not found!" << std::endl;
            continue; //Next Blob
        }
        //////////////////
        ///Make Fish Contour Only IMage
        /// /////////////////
        sfish.blobLabel = blob->label;
        cv::drawContours( maskfishFeature, contours_body, (int)idxblobContour, CV_RGB(255,255,255), cv::FILLED);
        //maskedfishImg_gray.copyTo(maskedfishFeature,maskfishFeature);
        cv::GaussianBlur(maskedfishImg_gray,maskedfishFeature,cv::Size(11,11),5,5);

        //cv::drawContours(maskfishFeature,contours_body,(int)idxblobContour,CV_RGB(255,255,255),1,-1,hierarchy_body);



        ///Find Child contour with largest area
        int idxChild = hierarchy_body[idxblobContour][2]; //First Child
        int maxArea = cv::contourArea(contours_body[idxChild]);
        for (int kk=0; kk< contours_body.size();kk++)
        {

            if (hierarchy_body[kk][3] == idxblobContour) //Is this a child of this contour?
            {
                int area  = cv::contourArea(contours_body[kk]);
                if (maxArea < area ) //Larger Area?
                {
                    idxChild = kk; //Set new Child contour index to largest one
                    maxArea = area; //Set new largest Area
                    //std::cerr << "Found larger Child Blob" << std::endl;
                }
            }
        }
        if (maxArea < 10)
        {
            std::cerr << "Warning fishBody area too small A=" << maxArea << std::endl;
            continue ; //skip Processing
        }



         //if (  cv::pointPolygonTest(contours_body[i],centroid,false) < 0 )

        //

        //Find Enclosing Triangle of Child contour
        cv::minEnclosingTriangle(contours_body[idxChild],triangle[idxblobContour]);


        //Check for Fit errors
        for (int k=0;k<3;k++)
        {
            if (triangle[idxblobContour].size() > 0 )
            {
                if (triangle[idxblobContour][k].x <= 0 || triangle[idxblobContour][k].y <= 0)
                {
                    //redo fit on larger countour
                    cv::minEnclosingTriangle(contours_body[idxblobContour],triangle[idxblobContour]);
                    break;
                }
            }
            else
                //redo fit on larger countour
                cv::minEnclosingTriangle(contours_body[idxblobContour],triangle[idxblobContour]);
        }
        triangle[idxChild] = triangle[idxblobContour];


        //assert(triangle[i][0].x >= 0 && triangle[i][0].y >= -40);
        //assert(triangle[i][1].x >= 0 && triangle[i][1].y >= -40);
        //assert(triangle[i][2].x >= 0 && triangle[i][2].y >= -40);


        ///Map Keypoint Triangle features
        double dab = cv::norm(triangle[idxChild][0]-triangle[idxChild][1]);
        double dac = cv::norm(triangle[idxChild][0]-triangle[idxChild][2]);
        double dbc = cv::norm(triangle[idxChild][1]-triangle[idxChild][2]);
        //Find Triangle Width - Set point0 and Point1 to the triangle's base
        if (dab < dac && dab < dbc)
        {
            sfish.coreTriangle.at(0) = triangle[idxChild][0];
            sfish.coreTriangle.at(1) = triangle[idxChild][1];
            sfish.coreTriangle.at(2) = triangle[idxChild][2];

//            sfish.coreTriangle[0] =  triangle[idxChild][0];
//            sfish.coreTriangle[1] =  triangle[idxChild][1];
//            sfish.coreTriangle[2] =  triangle[idxChild][2];

        }
        else
        {
            if (dac < dab && dac < dbc)
            {
//                sfish.coreTriangle[0] =  triangle[idxChild][0];
//                sfish.coreTriangle[1] =  triangle[idxChild][2];
//                sfish.coreTriangle[2] =  triangle[idxChild][1];

                sfish.coreTriangle.at(0) = triangle[idxChild][0];
                sfish.coreTriangle.at(1) = triangle[idxChild][2];
                sfish.coreTriangle.at(2) = triangle[idxChild][1];


            }
            else
            { //dbc is the smallest

                sfish.coreTriangle[0] =  triangle[idxChild][1];
                sfish.coreTriangle[1] =  triangle[idxChild][2];
                sfish.coreTriangle[2] =  triangle[idxChild][0];

//                sfish.coreTriangle.at(0) = triangle[idxChild][1];
//                sfish.coreTriangle.assign(1,triangle[idxChild][2]);
//                sfish.coreTriangle.assign(2,triangle[idxChild][0]);

            }
        }

        //Position Tail Top To Body Peak
        cv::Point minLoc;
        cv::Point maxLoc;
        double minVal,maxVal;
        //minMaxLoc(InputArray src, double* minVal, double* maxVal=0, Point* minLoc=0, Point* maxLoc=0, InputArray mask=noArray())
        cv::minMaxLoc(maskedfishFeature,&minVal,&maxVal,&minLoc,&maxLoc,maskfishFeature );

       //Set To Fish Body core
        sfish.coreTriangle[2] = maxLoc; //

        //cv::rectangle(maskedImg, rectFeatures[i].boundingRect(), CV_RGB(255., 0., 0.));


            ///Fit Spline

            ///
            ///Draw body centre point/Tail Top
            //Centroid
            cv::circle(frameMasked,centroid,10,CV_RGB(0,10,200));
            //Isolate Body from Eyes From Laplaced Image - So contour can trace them



            //Tail Top
            cv::circle(frameMasked,sfish.coreTriangle[2],15,CV_RGB(20,20,180),3);
            //Contour Eyes on Laplace Image - Segment Eye Mask
            int distToEyes = cv::norm(sfish.coreTriangle[2]-sfish.coreTriangle[1])/2;
            cv::circle(framelapl,sfish.coreTriangle[2],distToEyes,CV_RGB(255,255,255),6,cv::FILLED); //Mask Body
            //Mid Eye Position
            cv::Point midEyePoint = sfish.coreTriangle[0]-(sfish.coreTriangle[0] - sfish.coreTriangle[1])/2;
            cv::Point vecMidlEye = sfish.coreTriangle[2]+(midEyePoint-sfish.coreTriangle[2])*2;
            cv::line(framelapl,sfish.coreTriangle[2],vecMidlEye,CV_RGB(255,255,255),2,cv::FILLED); //Mask Body
            cv::findContours(framelapl, contours_laplace,hierarchy_laplace, cv::RETR_CCOMP,cv::CHAIN_APPROX_NONE , cv::Point(0, 0) ); //cv::CHAIN_APPROX_SIMPLE




            //LeftEye
            cv::circle(frameMasked,sfish.coreTriangle[0],8,CV_RGB(0,250,10),3);
            //RightEye
            cv::circle(frameMasked,sfish.coreTriangle[1],8,CV_RGB(250,0,10),3);

            cv::Point splinePoint[8];
            cv::Vec4f centreline;

//            cv::fitLine(contours_body[idxblobContour],centreline ,CV_DIST_L2,0,10,0.01);
//            //y = y0+m*l y0=centreline[3] centroid.y
//            int y0   = centroid.y;// centreline[3];
//            int x0   = centroid.x;// centreline[2];
//            double m =  (double)(centreline[1]/centreline[0]);
//            int bodyLength = 50;//(rectFeatures[i].boundingRect().size().height/2);
//            splinePoint[0].y =  y0+bodyLength*m;
//            //x = (y-y0)/m +x0 // x0=centreline[2]
//            splinePoint[0].x = bodyLength/m + x0;  //(splinePoint[0].y-y0)/m + centreline[2];
//            //x0,y0 cv::Point(centreline[2],centreline[3]
//            cv::line(frameMasked,splinePoint[0],centroid,CV_RGB(0,200,200),2);

            ////DRAW
            ///
            cv::drawContours( frameMasked, contours_body, (int)idxblobContour, CV_RGB(150,150,150), 1, 8,hierarchy_body);

            //Draw Child Contour
            cv::drawContours( frameMasked, contours_body, (int)idxChild, CV_RGB(250,50,50), 2,cv::LINE_8,hierarchy_body);

            //Draw Fitted Triangle
            for (int j=0; j<3;j++)
                cv::line(frameMasked,sfish.coreTriangle[j],sfish.coreTriangle[(j+1)%3] ,CV_RGB(0,100,220),3);

            //Draw Enclose Rectangle
            cv::Point2f featurePnts[4];
            rectFeatures[idxblobContour].points(featurePnts);

            for (int j=0; j<4;j++)
                cv::line(frameMasked,featurePnts[j],featurePnts[(j+1)%4] ,CV_RGB(210,00,0),1);



            //Spline
            /* polyline approximztion of the contour */
            std::vector<cv::Point> poly_spline;
            approxPolyDP(contours_body[idxblobContour], poly_spline, 4, false);

            //Draw Fitted Poly
            for (int j=0; j<(poly_spline.size()-1);j++)
                cv::line(frameMasked,poly_spline[j],poly_spline[(j+1)] ,CV_RGB(0,200,20),1);


        } //For Each FishBlob




    ///DEBUG show all contours
    for( size_t i = 0; i< contours_body.size(); i++ )
    {
         cv::drawContours( frameMasked, contours_body, (int)i, CV_RGB(0,0,250), 1,8,hierarchy_body);
    }



    ///DEBUG show all contours -Laplace
    for( size_t i = 0; i< contours_laplace.size(); i++ )
    {
         cv::drawContours( framefishMasked, contours_laplace, (int)i, CV_RGB(200,0,0), 1,8,hierarchy_laplace);
    }


    //framelapl.convertTo(framelapl, CV_8UC3);
    cv::imshow("Edges Laplace",framelapl);

    cv::imshow("Fish Detect",framefishMasked);
    cv::imshow("Threshold COMB",threshold_output_COMB);
    cv::imshow("Threshold H",threshold_output_H);

}

/**
* @function thresh_callback
*/
void thresh_callback(int, void* )
{

    if (g_BGthresh % 2 == 0)
        g_BGthresh ++;

    if (g_Segthresh < 4) g_Segthresh = 3;

    if (g_Segthresh%2 == 0)
        g_Segthresh++;

}
